## 集群计算概述
### 并行处理技术可以
- 可构建高性能的计算机
	- 流水线技术
	- 超标量和多处理机技术
- 可很好解决单个处理器瓶颈
### 多处理机系统用途
- 获得高速处理能力
- 实现高可靠性系统
- 实现资源共享和协同
### 三类高性能计算系统
- 高端系统：可实现最高性能但价格昂贵，如太湖之光等超级计算机
- 集群系统：低价格，构建周期短，但持续性能低
- 网络计算/云计算
### 并行计算的难点
- 并行性的描述和提取问题，关键理论问题
- 并行程序实现有难度
- 性能的极限问题（受限于1、2的进展）
### 基于网络的高性能计算环境
- 网格计算
> 网格基本技术要求标准：Ian Foster的网格标准
> 目标有资源共享、协同工作、通用开放标准以及动态功能
- 云计算
### 非冯诺依曼结构
- 非指令驱动式结构
- 光计算处理技术
- 量子计算技术
- 生物计算处理技术
## 相关理论基础
### 并行性的等级
- 指令内部的并行
- 指令间的并行
- 任务或进程之间的并行
- 作业或程序之间的并行
### 并行性开发的途径
- 时间重叠（流水线）
	- 概念：让多个处理过程在时间上相互错开，轮流重复的使用同一硬件设备的各个部分
	- 流水处理适合连续相同多操作/作业处理应用
- 空间重叠（资源重复）
	- 概念：通过重复设置硬件资源提高可靠性和性能
- 用户重叠（资源共享）
### 从控制工作流角度，目前有三大类体系结构
- 基于指令流计算的体系结构
	- 冯诺依曼计算机体系结构
	- 有CISC、RISC、DSP三种处理器
	- 运算指令：操作码+数据地址码
	- 指令流包括操作流和数据流，按照控制流原理工作
	- 应用最灵活，但是性能低，难以实现大规模并行
- 基于数据流计算的体系结构
	- ASIC电路，设计生产后逻辑功能固定
	- 速度快效率高，但是灵活性差
- 基于构令流计算的体系结构
	- 静态可重构
		- 可重构FPGA电路：一次上电，全芯片烧写
	- 动态可重构
		- 粗粒度FPGA芯片：根据应用对不同区域动态烧写
		- 重构通过构件实现：在任务处理过程中，可以通过构件（FPGA静态区域）定义rPU（FGPA动态区域）的功能
		- 高效率、灵活性好
>构件指功能模块，流件指在构建中流动的数据单元

### 计算机的概念分类模型
- Flynn分类法（针对冯式机）：
	- SISD单指令单数据流
	- SIMD单指令多数据流
	- MISD多指令单数据流
	- MIMD多指令多数据流
实现并行计算机结构的技术模型（基于指令流）：
- 并行向量处理机PVP
	- 特征：所有部件定制专用
	- 处理器为向量处理机，通过交叉开关访存
	- 易编程
- 对称多处理机SMP
	- 特征：使用商品化的微处理器每个处理器可以等同地访问SM、I/O及OS服务，使用高速缓存
	- 当代服务器和工作站架构
	- 易编程
- 大规模并行处理机MPP
	- 处理节点->商品微处理器
	- 分布式局部存储器
	- 定制互联网络
	- 异步MIMD，程序由多个进程构成，由进程传递消息
	- 不易编程，易扩展
- 分布共享存储多处理机DSM
	- 在每个处理节点设置高速缓存目录DIR，支持分布存储的数据一致性
	- 对于用户而言，形成了一个单地址的编址空间
- 工作站集群COW
	- 节点都是完整的工作站
![并行计算机结构的技术模型比较.](../assets/screenshots/25-11-16-1.png)
### 并行计算机访存模型
- 均匀存储访问模型UMA
	- 共享物理存储器、单一地址空间
	- 访问任何存储字访问延迟一致、共享同一总线或交叉开关
	- 每台处理器可带有高速缓冲cache
	- 外设也可以一定形式共享
	- 仅适合小规模
	- 为紧耦合系统，可由SMP和非对称处理机（分为主从处理器）应用
- 非均匀存储访问模型NUMA
	- 地址空间统一编址
	- 非均一内存访问
	- 每个处理器可带cache，且外设也可以某种形式共享
	- 可有层次性结构，可有全局共享存储器和群内共享存储器
	- 变种
		- 全高速缓存存储访问模型COMA
			- 无存储层次结构，缓存作为主存
			- 有分布的高速缓存目录
			- 高速缓存容量较大
		- 高速缓存一致性非均匀存储访问模型CC-NUMA
			- 将SMP机器作为一个单节点而彼此连接起来所形成的较大系统，实际上为DSM
			- 使用基于目录的高速缓存一致性协议
- 非远程存储访问模型NORMA
	- 所有存储器都是私有的，仅能由本地处理器访问
	- 以消息通信方式完成信息交换
### 并行计算性能分析模型
- Amdahl定律
	- 适用于固定负载，总问题规模不变，分析计算速度的加速比
	- 定义了串行程序并行化后加速比计算公式与理论上限
	- 假设：不能改善和可改善部分占总任务的比例固定
	- 加速比公式：$\frac{1}{(1-r)+\frac{r}{a}}$，r为可进行改善部分所占的比例，a表示进行改善部分改善的程度（处理器数量）
	- 结论1：加速效果与改进部分占总执行时间的比例有关
	- 结论2：任务规模固定时，在某个处理器数时，会达到加速比上限，再增加处理器个数没有意义
- Gustafsom定律
	- 任务规模增加，，每核处理问题规模不便，分析计算速度的加速比
	- 假设：不能改善部分的规模是固定的，可改善部分的规模是可变的
	- 加速比公式：$1+(n-1)a$，n表示处理器个数，a表示能改善部分的并行时间所占比例
- 性能上限分析
	- 强可扩展性：Amdahl定律
	- 弱可扩展性：Gustafson定律
- 粒度模型
	- 粒度是衡量计算任务所含计算量的尺度
	- 假设R代表程序执行时间，C代表用于通信/访存开销，使用R/C比值衡量任务粒度大小尺度
		- 粗粒度：R/C比值大，计算量大，通信/访存少，PVP、SMP适合
		- 细粒度：R/C比值小，计算量小，通信/访存少，MPP、DSM、COW适合
	- 假设每个任务执行时间以R为单位，每个任务获取数据时间以C为单位
		- M为子任务总数，M-K、K为两台机器任务分配数
		- 总处理时间：$R*max(M-K,K)+C(M-K)K$
		- 当$R/C<M/2$时，把所有任务分配到同一台处理机
		-  当$R/C>M/2$时，把所有任务平均分配给两台处理机
	- 优化方式
		- 采用通信与计算过程重叠的优化方法
		- 通过硬件/软件减少通信开销
	- 并行度M与粒度R/C具有trade off
- Roofline模型
	- 使用计算强度进行软硬件性能定量、直观分析
	- 算力$\pi$——每秒钟能完成的最大浮点运算数
	- 带宽$\beta$——获取数据的带宽上限
	- 计算强度上限$I_{max}=\frac{\pi}{\beta}$ ，在计算平台上，访存获取单位数据最多可用来进行多少次计算
	- ![Roofline.](../assets/screenshots/25-11-16-2.png)
	- 可以得到计算模型的计算强度，根据机器的最大计算强度进行比较，选择合适的机器
## 并行计算机Cache一致性
### 引发Cache一致性问题缘由
在多处理机系统中：
- 写共享数据操作时会引发Cache与主存以及各Cache之间数据不一致
- 进程迁移引发各Cache之间数据不一致
- I/O操作造成主存与各Cache中数据不一致
### 多机系统Cache一致性维护策略
基本思路：及时**更新**或**作废**主存和其他Cache中的数据（更新法一般不用）
4种一致性维护策略
- 基于Write Through策略
	- 基于WT策略的更新法
	- 基于WT策略的作废法
- 基于WB策略
	- 基于WB策略的更新法
	- 基于WB策略的作废法
策略实现方法
- 播写法（监听总线协议，广播写操作，适合总线结构）
- 目录表法（适合非总线互连网结构）
### 监听总线协议
基于总线的多处理机系统中，处理器可通过总线检测到所有对存储器正在进行的活动；如果总线业务破坏了cache数据块一致性状态，cache控制器就应该采取相应动作使本地副本更新或无效。
- 基于WT策略的一致性维护原理
	- 当处理器修改cache中的数据时，由总线使其他cache中的相同地址的数据均为无效
- 基于WB策略的一致性维护原理
	- 当处理器修改cache中的数据时，由总线使其他cache和主存中的相同地址的数据均为无效
- 典型一致性维护数据副本状态协议（一般使用作废法）
	- 2状态Cache协议
		- 每个数据块有`有效S`和`无效I`状态
		- 一致性四种操作
			- `Rr`和`Wr`其他处理机对该数据块副本的读写
			- `Rl`和`Wl`本地处理机对该数据块的读写
		- ![2状态Cache协议状态机.](../assets/screenshots/25-11-18-1.png)
	- 3状态Cache协议
		- 每个数据块有`不止一个数据块副本正确S`、`只有这个副本正确M（至少这个Cache数据块被写过一次，但memory内容未修改）`、`无效I`三种状态
		- 一致性四种操作
			- `Rr`和`Wr`其他处理机对该数据块副本的读写
			- `Rl`和`Wl`本地处理机对该数据块的读写
			- ![3状态Cache协议状态机.](../assets/screenshots/25-11-18-2.png)
	- 4状态Cache协议（MESI协议）
		- Write-Once策略：第一次写采用WT，之后的写采用WB（程序执行特点）
		- 把M状态分为Reserved状态和Dirty状态
		- 四种状态
			- Shared：从共享存储器读入并与存储器副本一致的cache数据块
			- Invalid：在Cache中找不到，或者Cache中的数据块与共享存储器中不一致的Cache数据块
			- Exclusive：从共享存储器读入的Cache数据只被写过一次，与共享存储器中的副本一致，且是正确副本（仅一个Cache和内存一致）
			- Modified：Cache中数据块不止一次被写过，共享存储器中数据块也不是正确数据块，唯一正确的数据块在Cache中（Cache和内存不一致）
		- ![4状态Cache协议状态机.](../assets/screenshots/25-11-18-3.png)
	- 5状态Cache协议（MOESI协议和MESIF协议）
		- 问题：其他CPU请求数据时，所有S状态下的CPU都发数据会导致数据拥塞
		- MOESI协议
		- ![MOESI状态Cache协议状态机.](../assets/screenshots/25-11-18-4.png)
		- O为1：Cache行中数据是系统中最新数据拷贝，且其他CPU一定具有该Cache行副本，其他CPU的Cache行状态只能为S，Cache行数据与主存中数据不一致
		- S位：Cache行状态为S时，其数据并不一定与存储器一致
			- 如果其他CPU的Cache中不存在状态为O副本，该Cache行中的数据与存储器一致
			- 如果其他CPU的Cache中存在状态为O的副本时，Cache行中的数据与存储器不一致
	- 目录表协议（基于互连网络）
		- 使用目录来记录共享数据的所有高速缓存数据行的位置与状态
		- 组件
			- 目录表
				- 存放与共享数据块副本相关的数据
				- 可以集中存放或分散存放
			- 目录项
				- 每个数据块一个目录项
				- 包含多个指针，指向该数据块的多个远程副本的地址
				- 一个重写位，用来说明是否有cache被允许数据块写入
		- 全映射目录
			- 在存储器中，每个目录项中有N个处理机指针位和1个重写位C
			- 处理机指针位：表示相应处理机Cache中对应块状态
			- 重写位：如果为1，表示有且仅有一个处理机指针位为1，且该处理机可对该块写操作
		- 有限目录
		- 链式目录
	- MESIF协议（用于ccNUMA）
		- 解决基于点到点的全互连处理器系统的Cache共享一致性问题
		- ccNUMA架构使用目录表，不能使用总线监听
		- 多个处理器Cache数据副本中，只有1个Cache行状态为F，其他为S
		- Cache行状态位为F时，Cache中数据与存储器一致
## 互联网络
### 互连网络特性
概念
- 计算/处理单元、存储单元和I/O单元等称为节点
- 节点间通过互连网络连接以交换信息
- 节点度：与节点相连接的边数，是节点需要的I/O端口数
- 网络直径：任意两个节点之间最短距离的最大值
- 等分宽度：网络被切分成相等的两半，沿切口的最小边数
- 节点间线长：两个节点间线的长度
- 对称性：从任何节点看网络的拓扑结构都是一样的
- 寻径功能：实现节点与节点之间连接方法
互连网络的性能指标
- 通信时延：从源节点到目的节点传送一条消息所需的总时间。包括4部分：软件开销、通道时延、选路时延、竞争时延
- 网络时延：通道时延、选路时延
- 端口带宽：单位时间传送到其他端口的最大信息量
- 聚集带宽：从一半节点到另一半节点，单位时间传送的最大信息量
- 对剖带宽：最小对剖平面所有边单位时间传送的最大信息量
- 网络吞吐率：单位时间内网络可传送的数据包数，对应用程序性能也有比较大影响
## 寻径函数
如果将互连网络的N个输入端和N个输出端分别用整数0、1、…、N-1来表示，则寻径函数描述了相互连接的输出端号和输入端号之间的一一对应关系。
- 交换置换
	- 实现节点二进制编址中第k位值不同的输入端和输出端之间的连接
	- 主要用于构造立方体互连网络和超立方体互连网络
- 全混洗置换
	- 把节点的二进制编码循环左移一位
	- 每全混洗一次，循环左移一次，经过n次全混洗，可恢复到最初排序状态
		- 子洗牌（K位子洗牌是最低k位进行洗牌，高位不变）
		- 超洗牌（K位超洗牌是最高k位进行洗牌，低位不变）
- 蝶式置换
	- 节点编址的最高位和最低位交换
		- 子蝶式（K位子蝶式是取最低k位进行蝶式置换，高位不变）
		- 超蝶式（K位超蝶式是取最高k位进行蝶式置换，低位不变）
- 位序颠倒置换
	- 将输入端二进制地址的位序颠倒过来
- 移数置换
	- 在n位末尾加1，并取模$2^n$
- 恒等置换
	- 相同编号的输入端与输出端一一对应所实现的置换
- 逆置换
## 静态互连网络
入/出端节点固定
- 每种连接可用一种寻径函数表示
- 若存在m种连接，用m个寻径函数表示
拓扑：
- 一维线性阵列
- 环形互连网（移数置换）
- 树形网络
- 树网连接
- 金字塔连接
- 超立方体网
	- 路由方法：当前节点与目的节点编号从高位到低位依次比较，相同不动，不同则向该位取反的相邻节点移动
	- 改进
		- 带环立方体CCC
		- k元n立方体网络
## 动态互连网络
- 总线结构
	- 最简单结构
	- 处理机、存储模块及I/O作为节点连接到总线上
	- 各节点以均等竞争方式使用总线，但容易引发冲突
		- 结构改进
			- 多总线结构
			- 多层总线结构
	- 总线仲裁
		- 排队器（优先权编码器）
			- 当多个节点同时发出请求，排队器仲裁，仲裁结果经过译码器控制节点发送信息
		- 菊花链
			- 静态菊花链
				- 给每个节点分配一个固定优先权
				- 当多个节点同时申请使用总线时，具有最高优先权的节点使用总线
				- 通过响应线连接到总线控制器的位置决定节点的优先权
				- ![[25-11-21-1.png]]
			- 动态菊花链
				- 节点优先权动态变化
				- 每个节点的接口都有总线控制器功能
				- 担当总线控制器功能的节点决定节点优先权
				- ![[25-11-21-2.png]]
				- 节点优先权变化策略
					- 循环法（节点最高优先权依次循环，刚使用过总线的节点具有最低优先权）
					- 基于某种函数确定优先权
- 交叉开关
	- 任何时刻任何节点可以访问任一其他节点
	- 无冲突现象发生
- 多级互连网络
	- 速度高，灵活性好，传输率低于完全开关网络，适用于PE较多的情形
	- 开关形式
		- 2\*2交叉开关
	- 级间拓扑结构
	- 开关控制方式
		- 级控制（同一级开关只用一个控制信号）
		- 单元控制（每一个开关都有自己单独的控制信号）
		- 部分级控制
	- 示例
		- STARAN网络
		- Omega网络
		- Parker网络
			- 基准网的递归组成：任何一个$N\times{N}$的互连网络，可以由两个$\frac{N}{2}\times{\frac{N}{2}}$的子网络组成
		- 多级互联网中的路径冲突
			- 冲突解决办法
			- 两个多级开关网串接在一起（延迟较大）
		- 两个Omega网络相连得到$\pi$网
		- Benes网：两个基准网且级合并
		- Cantor网络
		- Banyan网络
			- 每个根节点对应下面各级都是一棵树
			- 可以实现目标节点地址寻址
		- Delta网络
			- 分组混洗
			- 用$a*b$的开关可以构成${a^n}\times{b^n}$的网络
			- 小规模时：MIN跳数少，成本低；但链路数少，总带宽低，容错差
		- Batcher-Banyan非阻塞动态网
### 消息传递机制
- 消息格式
	- 消息：节点间通信的逻辑单位；由任意数目的固定长度包组成；长度可变。
	- 包：节点间信息传输最小单位；包含寻径目的地址、顺序号和数据片；一般长64～512位。
	- 数据片：包由固定长度的数据片组成。寻径信息和序号形成头片，其余的片是数据片。一般8～16位。
- 寻径方式
	- 线路交换
		- 先建立好专有路径，再传递消息
		- 时延公式：$T=(L_t/B)\times{D}+L/B$，$L_t$为建立路径所需的寻径信息片长度，L为信息包的长度，D为经过的节点数，B为带宽
		- 缺点
			- 物理通道不共享
			- 开销大
	- 存储转发寻径
		- 当包到达中间节点时，首先被存入缓冲区，当所输出通道和接收节点包缓冲区可使用时，再传送给下一个节点
		- 时延公式：$T=D\times{L/B}$，L为信息包的长度，D为经过节点数，B为带宽
		- 缺点
			- 包缓冲区大，不利于VLSI（超大规模集成电路）实现
	- 虚拟直通寻径
		- 为了减少时延，没有必要等到整个消息全部接受后再作路由选择，只要收到消息头部即可判断寻径
		- 时延公式：$T=L_h+L/B$，$L_h$为基于消息寻径头部寻径时间
		- 缺点：遇到阻塞时，依然是存储-转发。节点需要包缓冲区大，包缓冲区独立在寻径芯片外，转发延时大
	- 虫蚀寻径
		- 节点的寻径器硬件中只设置片缓冲区
		- 消息从源节点传送到目的节点经过寻径器
		- 时延公式：$T=T_f\times{L/B}=(L_f/B)\times{D}+L/B$，$L_f$为片长度，$T_f$为片经过一个节点所需时间
		- 优点
			- 缓冲区较小
			- 网络传输时延低
			- 通道共享性好，利用率高
			- 易于实现选播和广播通信方式
		- 需要注意
			- 同一包中所有的片不可分离，以虫蚀方式顺序地发送
			- 只有头片知道包发往何处，所有数据片必须跟着头片
			- 不同的包可以交替地传送，但不同包的片不能交叉，否则它们可能被送到错误的目的地
		- 主要问题
			- 通道争用时，更容易引起阻塞、死锁
	- 死锁和虚拟通道
		- 由于缓存区或通道上的循环等待会引起死锁
		- 死锁解决策略
			- 防死锁路由算法
			- 增加物理硬件通道
			- 虚拟通道（适合虫蚀寻径）
				- 建立节点间逻辑链路
				- 物理链路通道由所有虚拟通道分时共享
	- 包冲突时处理策略
		- 包处理冲突策略不能解决死锁问题
		- 阻塞法
			- 控制简单，但可能会引起大面积阻塞
		- 扬弃并重发法
			- 控制简单，重发效果未知，会加大网络负载
		- 虚拟直通法
			- 不会浪费已经分配的资源，但需要一个能存放整个包的缓冲区
		- 绕道法
			- 需要按某种算法重新寻径
	- 防死锁寻径算法
		- 确定寻径
			- 预先确定源节点到目标节点的路径，与网络的状况无关
			- 网络资源利用率不高，会影响系统性能
			- 两种确定寻径方法
				- 二维网格中的X-Y寻径
					- 首先沿着X维方向确定路径，然后沿着Y维方向选择路径
					- 四种模式：东-北，东-南，西-北，西-南
					- 路由与源节点无关，先编址的高位相等，再低位相等
					- 特点
						- 无死锁：总是先沿X维方向寻径，然后再沿Y维方向寻径，寻径不会出现死锁或循环等待现象。
						- 可扩展：可以扩充到n维网络，如X-Y-Z三维等等。
						- 最短路径：可用于存储转发或Wormhole寻径网络，在源和目的节点之间形成一条距离最短的路径。
				- 立方体网络中的E立方体寻径（TODO）
		- 自适应寻径（Subnet法）
			- 当节点故障或链路故障、冲突时，不能绕道，需要自适应寻径
			- 在网格网络中，同一维的所有连接都使用多个虚拟通道
			- ![[25-11-21-3.png]]
			- 拆分成两个虚拟子网
			- 两个方向寻径使用不同的虚拟通道，不会构成环路
	- 通信模式
		- 模式分类
			- 单播模式
			- 选播模式
			- 广播模式
			- 会议模式
		- 寻径算法效率需考虑因素
			- 信道量：传输消息所使用的通道数
			- 通信时延：包最长传输时间
		- 不同寻径方式关注因素
			- 在虫蚀寻径方式下，关注信道量参数
			- 在存储转发网络中，关注通信时延
		- 如何选择选播和广播
			- 选播：使得网络流量（信道量）和时延最少
			- 广播：生成广播树
## 并行计算机系统结构
### UMA型并行计算机
- Bus多处理器系统
	- Bus是瓶颈，解决思路
		- 减少使用总线
			- 增加Cache
			- 开发数据局部性
		- 提高总线性能
			- 使总线性能更高
			- 多总线、多级总线
	- 总线仲裁
		- 集中式仲裁
		- 分散式仲裁
			- 静态菊花链
			- 动态菊花链
				- 优先权循环法
				- AB母线仲裁（TODO）
		- 需要解决饥饿问题
- Switch多处理器系统
	- Crossbar
		- 特点
			- 开关控制，速度快
			- 严重受PIN数量限制；开关数多，成本高
	- MIN（Multistage Interconnection Network）
		- 麻痹
			- 问题：数据在传输过程中，经过的路径过于集中造成的阻塞现象
			- 解决方法
				- 减少请求
					- 合并消息
				- 增加可选路径
					- 增加开关级数
					- 多重输出网络
- NUMA型并行计算机
	- CC-NUMA
		- HM中数据的管理方式
			- 全映射法
				- 第一位：C表示数据是否有效/可重写
				- 每个PU占一位：表示对应Cache是否包含本页
				- 管理位的多少与PU数有关
			- Limited Pointed法
				- 基本思想：同时使用同一副本的PU数不超过4
				- 其他PU使用时，进行替换
			- 指针法
				- HM存储一个指向使用该页PU编号的指针
				- PU依次存储指向下一个使用的PU编号的指针
				- 最后一个使用的PU指向结束标志
			- Cache一致性协议
				- 三状态协议
				- HM：U(没有被Cache)；S(Memory和Cache一致)；D(Memory和Cache不一致)
				- Cache：I(无效页)；S(共有页)；D(独有页)
				- CC-NUMA数据一致性维护太复杂，成本高，性能损失大；HM仅数据开始、结束用到，中间可以不保存/修改HM中数据块，但目录表是需要的。
	- COMA（Cache Only Memory Architecture）
		- 结构特点
			- 阶层Bus
			- 目录D用于存储页的位置信息
		- 数据的访问方式
			- 初始：数据随机分配在Cache，并在Directory记录
			- PU待访问数据通过Cache和Directory找到后，拷贝到本地Cache
			- 问题
				- 访问数据地址的虚拟化，cache数据变化时，目录需要重新映射
				- 分布式缓存比共享驻村中页的替换更复杂
		- COMA协议
			- I（Invalid）：无效
			- E（Exclusive）：其它位置不存在Copy
			- S（Shared）：在其它地方存在Copy
			- R（Reading）：发出读要求后的等待状态
			- W（Waiting）：发出其它Copy无效化的等待状态
			- A（Answering）：正在回答其它Processor的读要求
	- Dash多处理机系统
		- 高速地址映射D将全局地址翻译为本地地址
		- 采用分布式目录方式的缓存一致性协议，使用硬件保持缓存数据一致性，减少访问延迟
		- 网络接口含目录，目录具有与配置在群里主存相对应的项，并保持着其他群的缓存状态信息
		- 数据分布在各群的局部主存中，但有局部性的数据尽量分布在相应群中。（M中数据不移动，和COMA不同）
## NORA型并行计算机
- NORA型MPP
	- 结构特点
		- 不共享内存
		- 通过消息传送方式进行协调
		- 规模较大
	- 结构分析
		- 静态网连接
			- Mesh
				- 简单的网络结构和路由算法就能够构成Mesh
				- 但规模较大时，mesh的网络时延成为关键问题
			- 超立方体Hypercube
				- 性能优异，寻径简单
				- 节点度很大，实现成本高
			- CCC（Cube Connected Cycle）
			- k-ary n-cube Torus（超立方体改进）
			- RDT（mesh改进）
			- 静态不等距网（fat tree）
			- 动态不等距网（fat tree）
		- 任务的逻辑结构由算法决定
- NORA型集群COW
	- 消息的传输控制方式
		- VIA（virtual interface architecture）
		- RDMA（Remote Direct Memory Access）
	- 未来COW->MPP
## 节点并行技术
- 一般是SMP、cc-NUMA架构
- 芯片：定制、商用
- 多芯片、大容量内存、高速网络接口
- 处理器芯片：多核、众核、异构多核/众核（趋势）
- 协处理器加速
- 发展趋势应该是通用核心的计算地位将随着时间推移不断减弱，以协处理器为中心思想
- 实例
	- CELL
		- 采用协处理器技术
		- 异构多核
		- PPU：主处理单元（运行操作系统）
		- SPU：协处理器（运行应用程序相关的线程计算）
		- 负载均衡：应用程序的多个线程被平均分布到各个SPE
		- Cell只要求具备强劲的浮点效能，而对整数运算不作要求，因此通用的主核心可以非常精简，没有要求通用性和兼容性
	- Intel的Many Core
		- 采用类似Cell的专用化结构
		- 将对等设计的四核心处理器中的某一个或几个内核置换为若干数量的DSP逻辑
		- Many Core必须考虑兼容大量的X86应用软件，专用的任务居于从属性地位，仍然要求通用性和兼容性
	- MIC架构
	- 通用处理GPU——GPGPU
	- 国产
		- 神威
		- 飞腾
		- 迈创
		- 海光
		- 华为鲲鹏
## 资源管理与任务调度
### 多机操作系统概述
多级操作系统主要功能
- 多机系统中用中间件层实现，处于节点操作系统和用户层环境中间
- 由软件基础结构的两个子层组成
	- SSI（Single System Image）基础结构
		- 与节点操作系统联系在一起，提供对系统资源的统一访问
	- 系统可用性基础结构
		- 在各个节点提供可用性服务
		- 检查点设置和进程迁移
多机操作系统分类
- 主从型
	- 操作系统仅在指定的主处理机上运行
- 独立型
	- 每个处理机有自己操作系统或管理程序
- 浮动型
	- 主处理机可以从一个处理机浮动到另一个处理机
### 资源管理和调度（RMS）
- 原因
	- 提高系统效率和可靠性
	- 提高可编程性和易管理性
- 功能
	- 线程/进程迁移
	- 检查点
	- 容错
	- 搜索空闲周期
	- 减少用户干预
	- 负载平衡
	- 多应用程序队列
- 组成
	- 资源调度器
		- 组织管理好物理资源
	- 作业调度器
		- 任务和物理资源的有效匹配
		- 处理应用程序队列等待任务（Job Selection）
		- 资源定位和任务分配（Job Allocation）
		- 调度的基本单位：计算节点或更细粒度资源
- 调度概述
	- 在一组具有任意特性处理机中对一组进程进行调度
	- 性能指标（从最大化资源利用率，最快完成任务执行角度）
		- 最小完成时间
		- 最小平均等待时间
		- 所需最少处理机数
		- 处理机最大利用率
		- 处理机最小空闲时间
	- 两类调度策略
		- 确定性调度
			- 在求解问题前给出表示问题特征的所有信息，主要有任务运行时间和任务间关系
			- 分类
				- 单作业并行调度
					- 子任务之间有数据、控制等相关性，调度时必须考虑同步等问题
					- 实现
						- 非抢先调度方法
				- 多作业并行调度
					- 各作业之间无相关，独立执行，作业内子任务有相关
		- 不确定性调度
			- 系统运行过程中根据系统状态对任务进行分配
	- 两种调度实现方法
		- 抢先调度
		- 非抢先调度