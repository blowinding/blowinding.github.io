## ABSTRACT
ISP 通常会对用户流量进行限速（例如，使其符合用户所订购的带宽速率）。除了能够正确地执行目标速率之外，限速机制还必须在每个流量聚合内部支持丰富的速率共享策略（例如逐流公平、加权公平以及优先级调度）。同时，这些功能还必须具备良好的可扩展性，以高效支持数量巨大的用户规模。

目前主要有两类限速机制：**流量整形（traffic shaping）**和**流量监管（traffic policing）**。  
流量整形通过在队列中缓存数据包来强制执行目标速率和调度策略；而流量监管则是在不进行缓存的情况下，根据目标速率直接过滤（丢弃）数据包。

流量监管机制轻量且易于扩展，但无法支持复杂的策略执行，并且其速率控制效果往往较差（配置难度大、行为难以预测）。相比之下，流量整形能够很好地实现目标速率和丰富的调度策略，但代价是较高的系统资源消耗（包括内存和 CPU），从而限制了其可扩展性。

在本文中，我们探讨是否能够兼得二者之长——既具备流量监管的高可扩展性，又拥有流量整形在速率控制和策略执行方面的优良特性。我们给出了肯定的答案，并提出了一种系统 **BC-PQP**。

BC-PQP 通过以下两点增强了传统的流量监管机制：  
1）引入多个**虚拟队列（phantom queues）**，利用计数器来模拟缓冲区占用情况，从而支持丰富的策略执行；  
2）提出了一种新的**突发控制（burst control）机制**，实现队列参数的自动配置，以保证正确的速率执行。

我们基于 DPDK 将 BC-PQP 实现为一个中间盒（middlebox）。实验评估结果表明，BC-PQP 在速率和策略执行效果上接近流量整形机制，同时在效率上提升了 **7 倍**。
## INTRODUCTION
限速机制必须能够为每一个流量聚合（例如属于某个特定用户的一组流）**正确地执行其期望的总速率**。除此之外，它还必须满足两个重要要求:
- 限速机制应当能够支持在同一流量聚合内部对不同流之间实施多样化的速率共享策略。
- 速率和策略执行机制必须具备**高效率**。这一要求源于系统的运行规模——典型的 ISP 往往需要支持成千上万的用户。
由于在效率方面具有优势，**流量监管器（policer）** 逐渐成为更为常用的限速方案。然而，这种可扩展性也伴随着一些显著的缺陷：
- **典型的 policer 在设计上并不提供任何机制**，用于在每个被限速的流量聚合内部执行期望的速率共享策略；  
- **policer 的配置困难**，这往往会导致较差的速率执行效果，在“满足期望的平均速率限制”与“降低突发性和丢包率”之间存在明显的权衡
本文提出了兼二者之长的方案，通过使用虚拟队列（phantom queues）来实现 policer。
基于虚拟队列的 policer 在数据包到达时，如果虚拟队列中仍有足够的“容量”（等价于该数据包大小），就立即转发该数据包；否则就将其丢弃。每当成功转发一个数据包时，系统便在虚拟队列中“入队”一个与该数据包大小相同的**虚拟数据包**——这些虚拟数据包在实现上仅表现为字节计数器。虚拟队列以期望的速率进行“出队”，即通过递减相应的字节计数器来实现。
为了执行不同的速率共享策略，我们将这种基于虚拟队列的监管系统扩展为：**为每个流量聚合维护多个虚拟队列**。系统根据数据包头部字段中的流标识，将到达的数据包分类到某一个虚拟队列中，并按照前述方式，依据该虚拟队列的占用情况立即决定是转发还是丢弃该数据包。随后，系统按照期望的策略（例如优先级调度、轮询等，类似于流量整形器）对这些虚拟队列中的虚拟数据包进行“出队”（即递减对应的字节计数器）。

尽管当虚拟队列的容量足够大时，PQP 能够在**平均意义上**（跨越多个往返时延 RTT）正确地执行期望的速率限制，但在**更短的时间尺度**上，其瞬时速率可能会突发到远高于目标值的水平，并且这种突发性会随着队列规模的增大而加剧。

事实上，为了利用虚拟队列正确地执行平均速率限制，所需的**最小队列容量本身就非常大**：其数量级为 **O(BDP²)**（相比之下，使用真实数据包的流量整形队列只需要 **O(BDP)** 规模的缓冲区）。如此庞大的队列规模在 PQP 中会进一步放大突发问题——当系统中存在 **N 个活跃的虚拟队列**时，**最坏情况下的突发规模可能会扩大到原来的 N 倍**！
我们为虚拟队列设计了一种新的**突发控制机制**。该机制首先将每个虚拟队列的容量设置为足够大的值。然而，当某个虚拟队列的入队速率超过预设阈值时，我们会**虚拟地将该队列填满一些“魔法虚拟数据包”（magic phantom packets）**——这些数据包并不对应任何真实的数据包。通过这种方式填满队列，可以抑制流量突发并触发**提前丢包**。与此同时，队列本身仍然保持较大的容量（只是被这些以期望出队速率排出的魔法虚拟数据包所占据），从而满足**正确执行平均速率限制**所需的队列大小条件。
## BACKGROUND
### Traffic Shapers

### Traffic Policer
## Policers with Phantom Queues
### Policing with a Single Phantom Queue
可通过**虚拟队列（phantom queue）** 来实现这样的流量监管系统，其核心思想是：构造一个容量为 **B**、服务速率为 **r** 的（模拟）缓冲区。

- 当一个大小为 **s** 的数据包到达时，系统首先检查虚拟队列所模拟的缓冲区中是否还有足够的剩余容量。如果虚拟队列的剩余容量不少于 **s**，则系统**立即转发该（真实）数据包**，并代表该数据包在虚拟队列中“入队”一个大小为 **s** 的**虚拟数据包**。
- 如果虚拟队列已满（或其剩余容量小于 **s**），则系统直接**丢弃该（真实）数据包**。
- 虚拟队列中的虚拟数据包会以速率 **r** 被“出队”。需要注意的是，在整个过程中，我们**不会缓存任何真实数据包**——所有真实数据包在到达时都会被立即转发或丢弃。虚拟队列中的虚拟数据包在实现上仅通过**字节计数器**来表示，在发生虚拟入队或出队事件时对该计数器进行相应的递增或递减。
- 此外，与流量整形器不同，整形器需要按照速率 **r** 定期地对真实数据包进行出队操作；而在虚拟队列中，**虚拟出队操作可以进行批量处理**，仅在虚拟队列达到满状态时才需要执行。

以这种方式、使用**单个虚拟队列**实现的流量监管系统，其行为本质上等价于一个**桶容量为 B、速率为 r 的令牌桶过滤器（TBF）**，如第 2.2 节所述。
### Policing with Multiple Phantom Queues
一旦我们将流量监管器实现为一个**虚拟队列（phantom queue）**，就可以将其扩展为一个由 **N 个虚拟队列**组成的系统（类似于包含 N 个队列的流量整形器），以实现不同的速率共享策略。

- 当一个大小为 **s** 的数据包到达时，系统会根据数据包头部字段（例如流 ID、源–目的地址对的哈希值等），将其分类到 **N 个虚拟队列**中的某一个（记为 **Qᵢ**，其缓冲区大小为 **Bᵢ**）。
- 如果 **Qᵢ** 的剩余缓冲容量不少于 **s**，系统便立即转发该真实数据包，并通过将其字节计数器增加 **s** 的方式，在 **Qᵢ** 中为其“入队”一个对应的虚拟数据包。
- 若在考虑所有待处理的虚拟出队操作后，**Qᵢ** 的剩余缓冲容量小于 **s**，则该数据包会被直接丢弃。

虚拟队列中的虚拟数据包（即字节计数器）会按照期望的策略进行“出队”，也就是递减相应的计数器。

e.g. 为了实现**逐流公平（per-flow fairness）**，系统可以为每一个流维护一个虚拟队列（或者通过对数据包头部中的流标识进行哈希，将多个流近似地映射到 **N 个虚拟队列**中），并以**总速率 r** 按照**轮询（round-robin）** 方式从所有非空的虚拟队列中对虚拟数据包进行出队。

- 这种仅通过计数器维护的虚拟系统，与一个通过逐流队列存储真实数据包、并以总速率 **r** 采用轮询方式进行服务的流量整形系统在行为上是**完全等价的**。
- 这种**包含多个虚拟队列的流量监管系统**称为 **PQP（Phantom Queue Policer）**
- 使用术语“对应的流量整形系统（analogous shaper system）”来指代这样一种假想的整形器：它在真实数据包上执行与 PQP 在虚拟数据包上所采用的**相同入队与出队策略**
### Scope and Properties of PQP
需要注意的是，**PQP 直接在虚拟数据包（phantom packets）上执行期望的策略**（这些虚拟数据包在实现上仅以计数器的形式维护）。这些策略通过改变虚拟队列的占用情况，**间接地影响真实数据包的行为**，从而决定真实数据包是被转发还是被丢弃。真实数据包与虚拟数据包在行为上的这种差异，使得 PQP 在可实现的策略类型上受到一定限制。
#### 限制一：入队后不可丢弃（No drop after enqueue）
第一个限制源于这样一个事实：**PQP 在数据包到达时就决定其命运**（转发或丢弃）。如果对应的虚拟队列当前的占用情况允许该数据包被转发，那么该数据包会被**立即转发**，同时其虚拟副本会被“入队”（并假设该虚拟数据包最终一定会被出队）。按照这种设计，PQP 无法模拟那些**在数据包入队之后，其命运仍可能发生变化的策略**。
#### 限制二：速率共享策略的适用范围
第二个限制源于这样一个事实：在 PQP 中，**真实数据包与虚拟数据包的出队时间并不一致**。因此，尽管 PQP 在虚拟数据包上执行了与“对应流量整形系统”对真实数据包所采用的相同策略，但这些**具体的时间行为并不会映射到真实数据包上**。
其结果是，PQP **无法执行与数据包精确时序或调度顺序相关的策略**——一个在时间 _t_ 到达 PQP 的数据包，要么在 _t_ 时刻被丢弃，要么在 _t_ 时刻被立即转发。
尽管 PQP 无法控制**细粒度的数据包时序**，但它可以在**平均意义上**（即在更长的时间尺度上）执行不同的速率共享策略，具体体现为如何将总速率 **r** 在各个队列之间进行分配。
**PQP 在设计上保证了以下几个关键性质，使其能够在平均意义上执行上述速率共享策略：**

- **性质 1（Property 1）**  假设进入 PQP 系统的数据包集合与进入其对应流量整形系统（analogous shaper system）的数据包集合完全一致，那么如果某个数据包在整形系统中于时间 **$t_d$** 被出队，其对应的虚拟副本在 PQP 系统中也会在**相同的时间 $t_d$** 被出队。
- **性质 2（Property 2）**  如果某个（真实）数据包被 PQP 转发，那么其对应的虚拟副本最终一定会被 PQP 出队。
- **性质 3（Property 3）**  如果 PQP 在时间 **$t_e$** 转发了一个（真实）数据包，那么该数据包的虚拟副本会在时间 **$t_e$** 被入队到虚拟队列 **Qᵢ** 中，并在$t_d=t_e+D(i,t_e)t_d = t_e + D(i, t_e)t_d​=t_e​+D(i,t_e​)$时刻被出队，其中 **D(i, $t_e$)** 表示**虚拟排队时延**，即在 **$t_e$** 之前在 **Qᵢ** 中累积的虚拟队列需要被排空所需的时间。
可以结合上述性质来理解 **PQP 如何有效地执行速率共享策略**。
- 根据**性质 1**，如果一个对应的流量整形系统将总速率 **r** 在 **N 个队列**之间进行分配，使得队列 **Qᵢ** 以速率 **rᵢ** 得到服务（例如通过加权轮询、优先级调度，或它们的分层组合实现），那么对应的 PQP 系统也会以速率 **rᵢ** 对 **Qᵢ** 中的虚拟数据包进行出队。
- 根据**性质 2 和性质 3**，如果 **Qᵢ** 中的虚拟数据包以速率 **rᵢ** 被出队，那么在**平均意义上（跨越较长时间尺度）**，对应的真实数据包同样会以速率 **rᵢ** 得到服务。
- 真实数据包的**瞬时速率**相对于其理想的虚拟速率偏离多少，取决于**虚拟排队时延**；而虚拟排队时延又由**虚拟队列的容量**决定（该容量控制了 PQP 系统允许的突发程度）。我们将在第 3.4 节中对此进行更为形式化的分析，并在第 4 节中提出一种有效限制突发的机制。
- 此外需要注意的是，**性质 1 成立的前提是假设 PQP 系统与对应整形系统接收到的输入数据包集合完全一致**。然而，在 PQP 中，数据包实际被发送的时间偏差会影响拥塞控制算法的反馈回路，从而改变后续数据包的到达速率。尽管存在这一影响，我们在第 6 节的实验评估表明，PQP 在速率与策略执行方面的表现仍然**与对应的流量整形系统高度接近**。
### Bounds on Rate and Policy Enforcement
考虑一个大小为 **B**、以速率 **r** 提供服务的虚拟队列（phantom queue）**Q**。设在时间 **t** 时，虚拟队列的长度（即模拟缓冲区中的字节数）为 **L(Q, t)**。该队列长度决定了在时间 **t** 被发送的数据包所经历的虚拟排队时延。

在任意时间区间 **Δt = t₂ − t₁** 内，只要虚拟队列 **Q** 的占用量始终不为零，即  
$$  
L(Q,t) > 0,\quad \forall t \in (t_1, t_2),  
$$
则在该持续时间 **Δt** 内所强制执行的速率被界定在  
$$
(r \pm B/Δt)^+  
$$
之内。

已知在 **t₁ < t < t₂** 期间 **L(Q,t) > 0**，因此队列 **Q** 会持续以速率 **r** 出队虚拟数据包。在时间 **Δt** 内，它共出队 **rΔt** 字节。

因此，在区间 **(t₁, t₂)** 内，队列 **Q** 所接受的数据量 **A(t₁, t₂)** 可表示为：  
$$
A(t_1, t_2) = \big(L(Q,t_2) - L(Q,t_1) + rΔt\big)^+  
$$
其中 ((v)^+ = \max(0, v))。

由于  
$$
0 < L(Q,t) \le B,  
$$
我们可以得到在该时间段内可接受数据量的上下界。

**上界：**  
当 (L(Q,t_1)=0)，且 (L(Q,t_2)=B) 时，  
$$
A_{\max}(t_1,t_2) = rΔt + B  
$$

**下界：**  
当 (L(Q,t_1)=B)，且 (L(Q,t_2)=0) 时，  
$$
A_{\min}(t_1,t_2) = (rΔt - B)^+  
$$

因此，在持续时间 **Δt** 内，被接受的数据量满足：  
$$
A(t_1,t_2) = (rΔt \pm B)^+  
$$

将上式除以 **Δt**，即可得到在该时间区间内实际被强制执行的速率 **r′**。当 **Δt** 增大时，实际执行速率逐渐逼近虚拟队列的出队速率 **r**：  
$$
r' = \lim_{\Delta t \to \infty} \frac{A(t_1,t_2)}{\Delta t}  
= \lim_{\Delta t \to \infty} (r \pm B/Δt)^+ = r  
$$

图 3 展示了一个被限制在 10 Mbps 的 Reno 流的情况。图中的虚线表示根据定理 1 得到的理论速率误差界，而阴影区域表示实际测得的速率误差。随着 **Δt** 的增大，速率误差会不断减小。

需要注意的是，上述结果仅在虚拟队列在整个 **Δt** 时间内保持非空时才严格成立。如果虚拟队列在某段时间内为空，则所执行的速率将低于 **r**。这种情况可能发生在以下两种情形中：
1. 数据包到达速率（即业务需求）本身低于 **r**；
2. 业务需求高于 **r**，但队列容量不足，在典型拥塞控制行为下导致队列被耗尽。
现在考虑一个由 **N** 个虚拟队列组成的系统，其以累计速率 **r** 提供服务，并按照期望策略（§3.3 中讨论）将 **r** 分配给各个虚拟队列 **Qᵢ**，使其分别以速率 **rᵢ** 被服务。若每个队列的大小为 **Bᵢ**，则可由上述定理得到如下结论：

如果某个虚拟队列 **Qᵢ** 在持续时间 **Δt** 内保持非空，且其虚拟出队速率为 **rᵢ**，则其在该时间段内所强制执行的实际速率满足：  
$$
r'_i = (r_i \pm B_i/Δt)^+  
$$
进一步，对所有队列求和，可得到系统整体强制执行速率的界：  
$$
r' = (r \pm \sum_{i=1}^{N} B_i / Δt)^+  
$$
因此，若每个虚拟队列的大小均为 **B**，则整体强制执行速率为：  
$$
r' = (r \pm NB/Δt)^+  
$$
上述定理带来两个关键结论：
1. **只要虚拟队列保持非空，PQP 在真实数据包上强制执行的平均速率，在足够长的时间尺度上将与期望速率（即在虚拟数据包上执行的速率）一致。**
2. **在较短时间尺度上，真实速率与虚拟速率之间的偏差由虚拟队列的大小所界定。**
    - 虚拟队列过大，会导致瞬时执行速率显著高于期望速率（即产生较大的突发流量）；
    - 虚拟队列过小，则可能导致虚拟队列在某些时刻变空，从而使瞬时速率甚至平均速率低于期望值。
### Sizing the Phantom Queues

**幻影队列（phantom queue）的容量配置准则**取决于多个因素，例如限速速率 (r)、RTT 以及流所采用的拥塞控制协议。下面我们分析，为了实现**正确的平均速率约束**，幻影队列应当如何进行容量配置。

在 §3.4 中，我们对强制执行速率给出的界限是以**队列在给定时间区间内始终保持非空**为前提条件的。因此，为了达到这些界限，幻影队列必须足够大，使得一个**始终有数据可发送（backlogged）**、且其发送速率高于被限速速率 (r) 的发送端，其拥塞控制协议能够持续将该队列保持为非空状态¹。这一点与我们在分析**真实数据包的整形队列（shaper queue）** 容量配置时的思路是类似的 [9]。  
然而，由于**幻影数据包出队的时间与真实数据包发送时间之间存在时序差异**，以及这种差异对拥塞控制反馈回路的影响，最终得到的结论（即所需队列大小）与真实队列有着显著不同。

我们考虑当前生产环境中常用的几种拥塞控制协议：Cubic（大多数用户的默认协议 [19]）、New Reno（Netflix 使用 [47]）、以及 BBR（Google 和 YouTube 使用 [3,10]）。幻影队列的容量 (B) 应足以支持上述任意一种协议。其中，**Reno 系列协议对队列容量的要求最高**（本文中“Reno”同时指 Reno 和 New Reno，两者的核心逻辑一致，仅在快速恢复阶段有所不同）。因此，只要按 Reno 的需求来配置幻影队列容量，就可以保证对其他协议也能实现正确的速率约束。

对于存放真实数据包的整形队列，一个经验法则是：只需 **$O(\mathrm{BDP})$** 规模的缓冲区，就可以保证在 Reno 发送端始终有数据可发送的情况下，队列保持非空 [9]，其中 BDP 表示网络的带宽–时延积（bandwidth-delay product）。

相比之下，我们发现：**为了在幻影队列中保持一个 backlogged 的 Reno 流始终占用队列，需要将队列容量配置为 $O(\mathrm{BDP}^2)$**。更具体地说，为了对 Reno 流实现正确的速率约束，幻影队列的容量至少应为：

$$
\frac{\mathrm{BDP}^2}{18 \times \mathrm{MSS}} ;\text{字节}  
$$

其中  
$$
\mathrm{BDP} = r \times \mathrm{RTT}  
$$
$r$ 是幻影队列的出队速率，RTT 是该流的往返时延。

这一结果来源于我们在附录 A 中的分析：为了维持平均速率为 (r)，Reno 流在稳态的 AIMD（加性增加、乘性减少）阶段，其**瞬时发送速率需要在 $\frac{2r}{3}$ 到 $\frac{4r}{3}$ 之间波动**。要支持这种速率波动，幻影队列必须具备至少上述规模的缓冲能力。

还需要注意的是，在稳态下，**队列容量的上界并不关键**。一旦幻影队列被填满，它会自动以速率 $r$ 为新到达的数据腾出空间。


与真实数据包队列相比，幻影队列需要更大缓冲区的根本原因在于：**幻影队列不会对真实数据包引入排队时延**。

在真实队列中，当流的拥塞窗口（cwnd）超过 BDP 时，多余的数据包会被排队，并以速率 (r) 出队，从而引入额外的排队时延（叠加在基础 RTT 之上）。只有当该窗口内的所有数据包的 ACK 都返回发送端后，cwnd 才会增加 1。因此，当下一次由于 cwnd 增加而产生的新数据包到达队列时，前一轮 cwnd 中的所有数据包已经发送完毕，队列中的**驻留队列长度**在每次 cwnd 更新后只增加 1 个数据包。

而在幻影队列中，不论幻影队列实际需要多长时间才能被清空，**对应于整个 cwnd 的 ACK 都会在一个基础 RTT 内返回**。由于反馈回路中不包含排队时延，当下一轮 cwnd 的数据包到达时，前一轮中 **$(\mathrm{cwnd}-\mathrm{BDP})^+$** 个幻影数据包仍然滞留在队列中。因此，在真实队列中每次 cwnd 更新只会使队列增加 1 个包，而在幻影队列中，队列长度会增加 $(\mathrm{cwnd}-\mathrm{BDP})^+$ 个包。

因此，幻影队列必须足够大，以容纳这些额外累积的幻影数据包。

如果按 $O(\mathrm{BDP}^2)$ 的规则配置幻影队列容量，确实可以在稳态下对所有拥塞控制协议实现良好的速率约束，但这也会带来一系列问题。

首先，它会在流的**慢启动阶段**引发极大的速率突发。举例来说，假设我们希望通过幻影队列强制执行 15 Mbps 的速率限制，并按最大 RTT 为 100 ms 来配置队列容量（约 1.4 MB）。若一个 RTT 为 10 ms 的流经过该幻影队列，在慢启动阶段（假设 Linux 默认初始 cwnd 为 10 MSS），它可以在 100 ms 内突发到 **143 Mbps** 的速率。

这还会导致较高的丢包率：慢启动结束时 cwnd 已经增长到非常大的值，需要经过多轮丢包和 cwnd 减半，才能回落到与 BDP 相当、从而实现正确速率约束的水平。
### Burst Controlled PQP

一旦幻影队列变为满状态，只要其大小超过 Reno 所需的最小要求，那么**无论队列有多大**，在稳态下都可以实现**正确的平均速率约束**。换言之，在流的稳态阶段，为了实现正确的速率约束，幻影队列的大小并不存在一个严格的上限。

因此，与其去回答一个更加复杂的问题——即如何动态地调整队列大小（而这个问题的答案取决于多种因素，例如流所使用的拥塞控制协议、RTT、所需约束速率 (r)，以及其他流的需求）——我们转而思考：**如何在不产生大规模突发（burst）的情况下，让流尽快进入稳态？**

在上一节中我们已经看到，为了约束速率为 (r)，我们必须允许一定程度的速率波动。例如，对于 Reno，稳态下其发送速率会在 $\frac{2}{3}r$ 和 $\frac{4}{3}r$ 之间振荡。然而，任何**超过这一范围的突发流量都是不希望出现的**。

因此，我们提出了一种**主动的幻影队列管理机制**，其目标是在仍然实现正确速率和策略约束的前提下，尽量减少突发。

我们的设计基于如下观察：  
一旦一个**尺寸合适的幻影队列**被填满，对于一个需求大于 (r) 的饱和流而言，它会在稳态（例如 TCP Reno 的 AIMD 阶段）中尝试保持该队列始终为满状态，而这正是实现正确平均速率约束的关键。

然而，在流的起始阶段（即慢启动阶段），由于幻影队列最初为空，流可能会以**极高的速率突发发送**，直到队列被填满之后才退出慢启动阶段。

**我们的关键洞察是：我们并不需要等到幻影队列真的被填满，才让流退出起始阶段。**

相反，当流的发送速率超过某个**上阈值**（例如 (\frac{4}{3}r)，即 Reno 稳态下的最大速率）时，我们可以“**魔法般地**”直接将幻影队列填满。  
类似地，当流的发送速率低于某个**下阈值**（例如 (\frac{2}{3}r)，即 Reno 稳态下的最小速率）时，我们再将这些“魔法包”移除。

我们为一个包含 (N) 个幻影队列的 PQP 系统维护以下额外参数：

1. 上阈值乘子 $\theta^+$
    
2. 下阈值乘子 $\theta^-$
    
3. 时间窗口长度 $T$

当一个数据包被入队到幻影队列 $Q_i$ 时，我们首先估计该队列的**期望出队速率** $r_i^*$，并计算在时间窗口 $T$ 内该队列期望能够出队的字节数：

$$
X_i = r_i^* \cdot T  
$$

其中 $r_i^*$ 可以根据当前活跃队列集合以及速率共享策略直接计算得到。例如：

- **公平共享**：  
    $$  
    r_i^* = \frac{r}{\text{活跃队列数}}  
    $$
    
- **优先级调度**：  
    若 $Q_i$ 是当前最高优先级的活跃队列，则 $r_i^* = r$，否则为 0。
    

基于此，我们定义两个阈值：

- 上阈值：  
    $$
    X_i^+ = \theta^+ X_i  
    $$
    
- 下阈值：  
    $$
    X_i^- = \theta^- X_i  
    $$

如果在当前长度为 $T$ 的时间窗口内，幻影队列 $Q_i$ 接受的数据量超过 $X_i^+$，我们就**向该队列中填充“魔法幻影包”**，即将其字节计数器增加：

$$
M_i = B - L(Q_i, t)  
$$

其中 $B$ 是队列容量，$L(Q_i,t)$ 是当前队列占用。

我们会记录每个队列中加入的魔法包数量；当在时间窗口 (T) 内接受的数据量低于 $X_i^-$ 时，我们会将这些魔法包全部移除（即相应减少字节计数器）。

采用该机制的 PQP 系统被称为 **BC-PQP（Burst-Controlled PQP）**。

在 BC-PQP 中，每个幻影队列 $Q_i$ 的最大突发量不超过 $X_i^+$。如果将 $T$ 设为与 RTT 同量级，那么该突发规模是 **O(BDP)** 的。

在整个聚合流量中，对于任意速率共享策略，总突发不超过：

$$
N \cdot \theta^+ X  
\quad \text{其中 } X = \sum_{i=1}^N X_i  
$$

而对于公平共享和优先级等常见策略，平均突发会显著更小。

- **公平共享的最坏情况**：  
    若在时间窗口 (T) 内，(n) 个流依次变为活跃，则突发形成一个调和级数：  
    $$  
    \theta^+ X \left( \ln n + 0.5772 \right)  
    $$
    当 $n=64$ 时，大约为 $4.72 \times \theta^+ X$。
    
- **优先级调度**：  
    若有更高优先级队列处于活跃状态，则低优先级队列的 $X_i = 0$。
    

此外，如 §3.4 所示，随着队列保持满状态的时间变长，这种有限突发的代价会进一步被摊销。

我们将 (T) 配置为尾 RTT（例如 100 ms），以获得合理的入队和出队速率估计；  
并将 $\theta^- = 0.5$、$\theta^+ = 1.5$（基于 New Reno 的需求）。

这些配置在避免不必要突发的同时，仍能保证正确的速率约束。

图 5b 显示，在存在 8.5 Mbps 次级瓶颈的情况下，BC-PQP 能够以非常小、受控的突发，实现 4 个流之间公平共享 7.5 Mbps。

1. **幻影队列大小 (B_i) 如何设置？**  
    虽然 BC-PQP 在达到上阈值后会自动填充队列，但我们仍建议将队列大小设置为 **约 2 倍的 $O(BDP^2)$**，以防止恶意流以略低于上阈值但高于 (r) 的速率长期发送。
2. **为什么在流变为不活跃时移除魔法包？**  
    这样可以立即将空余带宽分配给其他活跃流。若不移除，在普通 PQP 中，幻影队列需要很长时间才能自然排空，从而导致暂时性的速率不足。
3. **BC-PQP 如何实现自动配置？**  
    BC-PQP 会独立估计每个队列的 $r_i^*$，并随着活跃队列集合的变化自动调整阈值。这避免了难以调优的静态配置，并且可自然扩展到任意速率共享策略。
    