## ABSTRACT
可编程分组调度使得调度算法可以直接被编程进数据平面，而无需更改硬件。现有方案要么尚未在交换机 ASIC 上实现硬件支持，要么需要多个严格优先级队列。我们提出了 **Admission-In First-Out（AIFO）队列**，这是一种新的可编程分组调度方案，仅使用**单个先进先出（FIFO）队列**即可实现。

AIFO 的提出源于两个近期趋势的交汇：**交换机中的浅缓冲（shallow buffers）** 以及**端主机中快速收敛的拥塞控制算法**。这两者共同导致了一个简单但关键的观察：在现代数据中心网络中，决定一个流完成时间（FCT）的关键因素，往往是**哪些分组被接收进入队列或被丢弃**，而不是这些分组从交换机中离开的具体顺序。

AIFO 的核心思想是维护一个**滑动窗口**，用于跟踪最近到达分组的“排名”，并在分组到达时，计算该分组在窗口中的**相对排名**，从而据此进行**准入控制（admission control）**。

在理论上，我们证明了 AIFO 相对于 **Push-In First-Out（PIFO）** 能够提供**有界的性能保证**；在实验上，我们对 AIFO 进行了完整实现，并在多种真实工作负载下对其进行了评估，结果表明 AIFO 能够很好地逼近 PIFO 的性能。

更重要的是，与 PIFO 不同，AIFO 可以在**现有硬件上以线速运行**，并且只需要**极少的交换机资源**——**最少仅需一个队列**。
## INTRODUCTION
**Push-In First-Out（PIFO）队列**是一种广受关注的可编程分组调度抽象 [3, 47]。在 PIFO 中，每个分组都会被赋予一个 **rank（排名）**，并存储在一个**按 rank 排序的队列**中。新到达的分组会根据其 rank 被插入到队列中的相应位置，而分组始终从队首被取出。通过改变 **rank 的计算函数**，即可在 PIFO 之上实现不同的分组调度算法。

在本文中，我们提出了 **Admission-In First-Out（AIFO）队列**，这是一种新的可编程分组调度方案，**仅使用一个先进先出（FIFO）队列**即可实现。FIFO（drop-tail）队列是最简单的一类队列，能够以线速运行，并且几乎在所有交换机中都可用。因此，AIFO 非常适合在高速交换机上以线速实现。本文不仅给出了 AIFO 的具体设计，还在现有硬件（**Barefoot Tofino**）上实现了 AIFO，对硬件原语的要求极低——**只需要一个 FIFO 队列**，而非多个严格优先级队列。

AIFO 的提出源于数据中心网络中两个近期趋势的交汇：**交换机中的浅缓冲（shallow buffers）** [5]，以及**端主机中实现的快速收敛拥塞控制协议** [22]。二者共同显著降低了网络内部的排队时延，这一点在数据中心环境中尤为重要，因为低时延对具有严格服务等级目标（SLO）的实时在线服务至关重要 [5]。在这样的背景下，我们观察到，在现代数据中心中，**决定性因素往往是交换机接收（入队）或丢弃了哪些分组，而不是分组离开交换机的具体顺序**。例如，当一个“大象流”与两个“老鼠流”竞争时，**丢弃大象流的分组**，相比调整分组出队顺序，对老鼠流的流完成时间（FCT）影响更为关键，尤其是在队列长度保持较小、任一时刻仅有少量分组驻留的情况下。

基于这一洞察，本文所要解决的核心技术挑战是：**如何选择合适的一组分组准入队列**。理想情况下，AIFO 应当接纳与 PIFO 相同的分组集合，从而尽可能逼近 PIFO 的行为。AIFO 通过维护一个**滑动窗口**来跟踪窗口内近期分组的 rank，并在新分组到达时计算其**相对 rank**，据此决定是否接纳该分组，或者**即使队列仍有空间也主动丢弃该分组**。与传统的主动队列管理（AQM）方案不同，AIFO 是**基于相对 rank 进行丢包决策**，而不是依赖平均队列长度的阈值比较 [12, 34, 35]，或基于时延估计的方法 [32]。

在理论方面，我们证明了 AIFO 能够提供**接近 PIFO 的性能**；在实践方面，我们给出了具体的数据平面设计与实现，展示了如何在 **Barefoot Tofino** 上高效地实现 AIFO。AIFO 探索了一个颇具意义的设计问题：**实现可编程分组调度所需的最小硬件资源是什么？** AIFO 位于该设计空间的一个极端点——**只需要一个 FIFO 队列**。这一点不仅在理论上具有吸引力，也具有重要的现实意义。

我们与多家工业界合作伙伴（包括一家大规模搜索引擎公司和一家大型电子商务服务提供商）的交流表明，**物理队列是极其关键的资源**，通常被预留用于在多租户环境中实现应用之间的**强物理隔离与差异化服务**；而现代数据中心交换机中，物理队列资源本就十分紧张。与需要多个物理队列来实现分组调度的 **SP-PIFO** 不同，AIFO 使得运营者能够继续将物理队列用于多租户之间的强隔离和差异化保障，同时**额外利用 AIFO 对租户内部流量进行可编程调度**（例如使用 SRPT 来最小化流完成时间）。
## BACKGROUND AND MOTIVATION
### Programmable Packet Scheduling
可编程分组调度使得交换机中的分组调度算法可以在**无需更改交换机 ASIC** 的情况下进行修改。**PIFO** [47] 是一种用于可编程分组调度的方案，它包含两个组成部分：**PIFO 队列**和**rank（排名）计算模块**。每个分组都会关联一个 rank。PIFO 队列本质上是一个**按 rank 排序的优先级队列**：分组根据其 rank 被插入队列，并从队首（即 rank 最小的分组）出队。PIFO 的**可编程性**体现在 rank 计算模块中——在 PIFO 语境下，编程一个分组调度算法，指的就是**编程如何为每个分组计算 rank**。

一个简单的例子是编程 **SRPT（Shortest Remaining Processing Time）** [41]，用于最小化流完成时间（FCT），如图 1 所示。在该示例中，分组的 rank 就是该流的**剩余处理时间**（或等价地，流的剩余字节数）。需要注意的是，SRPT 要求端主机将剩余处理时间填入分组头部的某个字段中 [6, 41]，这一点与交换机内部的分组调度机制是正交的。基于这样的 rank 计算方式，PIFO 队列将优先调度剩余处理时间最短的分组，从而实现 SRPT。

一个更为复杂的例子是编程 **STFQ（Start-Time Fair Queueing）** [13] 以实现加权公平性，这同样如图 1 所示。在该示例中，分组的 rank 是其在 STFQ 中的**虚拟开始时间（virtual start time）**。虚拟开始时间的计算方式为：当前系统的虚拟时间与同一流上一个分组的虚拟完成时间二者中的较大值。系统的虚拟时间维护的是**所有流中最近一次出队分组的虚拟开始时间**。而某个分组的虚拟完成时间等于该分组的虚拟开始时间，加上该分组长度除以该流权重的结果。基于这种 rank 计算方式，PIFO 队列将优先调度虚拟开始时间最小的分组，从而实现 STFQ。

除了上述两个示例之外，已有研究表明，**PIFO 能够支持非常广泛的分组调度算法**，例如 **Least-Slack Time-First（最小松弛时间优先）** [23]、**Service-Curve Earliest Deadline First（SC-EDF）** [40] 等。
### Motivating Example
尽管 **PIFO** 是一种非常有吸引力的可编程分组调度方案，但在硬件中，尤其是在交换机 ASIC 上实现它存在很大挑战。**rank 计算组件**相对容易实现，可以作为一个数据平面中的分组事务（packet transaction）[46] 在现有可编程交换机上实现。主要的挑战在于 **PIFO 队列的实现**。现有交换机的数据平面不支持排序队列。虽然有一项工作提出了在数据平面以 1 GHz 支持排序队列的设计方案 [47]，但该方案仅提供设计，并未进行实际实现，而且可扩展性有限，只能支持几千条流。**SP-PIFO** [3] 提供了一种使用多个严格优先级队列（strict-priority queue）来近似 PIFO 队列的方案。然而，严格优先级队列是宝贵的硬件资源，因为商用交换机中的严格优先级队列数量有限，而且运营者希望将它们用于确保多租户之间的**强物理隔离**。

在本文中，我们的目标是设计一种**对可编程分组调度具有最小硬件需求的解决方案**。

为了找到这样的方案，我们从基础出发分析问题。考虑一个队列的**到达流量（arrival traffic）**和**离开流量（departure traffic）**：

- 当分组到达速率不高于链路速率（即离开速率的上界）时，**所有流量都是可接纳的**，不会出现持续排队。此时，无论队列是 PIFO、FIFO 还是其他类型，表现都没有区别。
    
- 区别出现在**到达速率超过链路速率**的情况，这可能由短时突发（microburst）或长期拥塞引起。这时，部分分组是**不可接纳的**，队列调度策略就很重要。
    

假设交换机收到**一波六个分组的突发流量**，队列有 4 个空位，初始为空。

1. **PIFO 行为**：
    
    - 前四个分组依次入队，排序后的队列为 `[1, 1, 4, 5]`
        
    - 第五个分组到达，rank = 2，PIFO 会将其插入队列，并因队列溢出而丢弃队尾分组，队列变为 `[1, 1, 2, 4]`
        
    - 第六个分组到达，再次丢弃队尾分组，最终队列为 `[1, 1, 2, 2]`
        
2. **FIFO 行为**：
    
    - 分组按到达顺序入队
        
    - 四个分组入队后，队列满，后两个分组无法入队
        
    - 最终队列为 `[1, 4, 5, 1]`
        

可以看出，PIFO 和 FIFO 的行为差别很大。

如果存在一个**事先知道分组精确到达模式的神谕（oracle）**，交换机可以在分组入队前进行**准入控制（admission control）**。

- 对图 2 中的例子：
    
    - 可以设定准入阈值为 3
        
    - 如果分组 rank ≤ 3，则入队，否则丢弃
        
    - 在此策略下，第二和第三个分组会被丢弃，最终队列为 `[1, 1, 2, 2]`
        

**结论**：在加入这样的准入控制后，FIFO 的行为可以在该例中**与 PIFO 完全一致**。
## DESIGN GOAL

基于前述示例所获得的洞察，我们可以将**分组调度问题转化为一个准入控制（admission control）问题**，并用**带准入控制的 FIFO** 来近似 **PIFO**。我们将这种方法称为 **AIFO**。我们的目标是**最小化理想情况（即 PIFO）与近似方案（即 AIFO）之间的差距**。

这一差距可以通过如下指标进行定量衡量：**PIFO 与 AIFO 实际出队分组集合之间的差异**。形式化地，设在时间 (t) 之前，PIFO 与 AIFO 已经出队的分组集合分别为 (P(t)) 和 (A(t))。我们定义

$$
\Delta(t) = \frac{|P(t)\setminus A(t)| + |A(t)\setminus P(t)|}{|P(t)| + |A(t)|}  
\tag{1}  
$$

来衡量 PIFO 与 AIFO 之间的差距。其中，$|P(t)\setminus A(t)|$ 表示集合 $P(t)$与 $A(t)$ 的差集大小，$|A(t)\setminus P(t)|$ 类似；$|P(t)|$ 和 $|A(t)|$ 分别表示集合 $P(t)$ 和 $A(t)$ 的基数。显然，$\Delta(t)\in[0,1]$，其值越大，表示 AIFO 与 PIFO 之间的差距越大。当 AIFO 与 PIFO 出队的分组集合完全相同时（即没有差距），$\Delta=0$；当二者出队的分组集合完全不同时，$\Delta=1$。

我们在理论上证明了：当系统处于**稳态（stationary）** 时，AIFO 与 PIFO 之间的差异可以忽略不计（§4）；并在实验上通过多种真实工作负载验证了 AIFO 在性能上**非常接近 PIFO**（§5）。

另一种可能的度量方式，不仅统计出队分组集合的差异，还考虑**分组出队顺序的不同**。图 3 给出了一个示例来说明这一点。该示例与图 2 类似，唯一的区别是图 3 中第三个和第四个到达的分组顺序被交换了。在这种到达序列下，AIFO 仍然接纳了与 PIFO 相同的一组分组，即 ({1, 1, 2, 2})，但二者的出队顺序不同：AIFO 的出队顺序为 ([1, 2, 1, 2])，而 PIFO 的出队顺序为 ([1, 1, 2, 2])。

我们认为，相比前一种指标，这种考虑出队顺序差异的度量**并不那么重要，甚至在某些情况下并不值得优化**。原因有二：

1. **数据中心网络的两个重要趋势**：  
    (i) 为了降低时延，现代数据中心正趋向于使用**浅缓冲（shallow buffers）** [5]；  
    (ii) 端主机侧采用**紧密的控制回路（tight control loops）** [22]。  
    这两个趋势的叠加，使得交换机队列中缓存的分组数量很少，从而使得 PIFO 与 AIFO 在分组出队顺序上的差异非常有限。由于我们本质上是在用 FIFO 队列来模拟 PIFO，因此希望保持队列尽可能浅，使分组在队列中的等待时间很短。实验结果（§5）表明，这种出队顺序上的差异**几乎不会影响诸如流完成时间（FCT）等流级指标**，AIFO 的行为与 PIFO 几乎一致。
    
2. **严格遵循 PIFO 反而会导致分组乱序（packet reordering）**，这是不理想的。  
    **SRPT** 被证明在最小化 FCT 方面具有近似最优性 [41]，其思想是根据剩余流大小对流进行调度，使小流优先于大流。然而，当 PIFO 被编程为使用“剩余流大小”作为 rank 来实现 SRPT（如图 1 所示）时，就会发生分组乱序：对于同一条流，后到达的分组具有更小的剩余流大小，因此如果多个分组同时在队列中，后到达的分组可能会被先调度。这是一个已知问题。**pFabric** [6] 通过引入一个称为**防饥饿（starvation prevention）**的机制来解决该问题：同一流内的分组按到达顺序出队，从而保证第一个分组不会被饿死；而在不同流之间，仍然使用 SRPT 决定优先调度哪一条流。
    

鉴于数据中心网络对低时延的强烈需求，**pFabric 可以说是可编程分组调度的“杀手级应用”**。然而，pFabric 无法由 PIFO 支持 [47]。出乎意料的是，**AIFO 的一个积极副产品是：它在设计上天然支持防饥饿机制，并且自动消除了分组乱序问题**。

综上所述，我们的目标是设计一种**具有最小硬件需求（即仅需一个队列）** 的算法，通过**接纳合适的一组分组**来最小化 $\Delta$，并保持队列缓冲较浅。该算法应当能够在**现有硬件的数据平面中实现并以线速运行**，同时保证在 $\Delta$ 指标下，**相对于 PIFO 具有有界的性能逼近**。
## AIFO DESIGN

### Key Ideas
AIFO 仅使用**一个 FIFO 队列**，而不是 PIFO 队列或多个严格优先级的 FIFO 队列。它在 FIFO 队列前增加了一个**准入控制（admission control）模块**，用于决定一个到达的数据包是被接收还是被丢弃。被接收的数据包进入队列并按照 FIFO 顺序发送，**无需额外的调度逻辑**。

准入控制的设计目标是最小化第 3 节中定义的 Δ，从而尽量缩小 AIFO 与 PIFO 之间的差距。AIFO 通过一种**二维准入控制机制**来近似实现 PIFO，该机制**同时考虑时间维度和空间维度**：

- **时间维度（temporal component）**：通过根据到达速率的波动，随时间动态调整准入阈值；
    
- **空间维度（spatial component）**：通过根据不同时间点上数据包的 rank（优先级）来决定准入阈值。
    
这两个维度共同作用，确保 AIFO 接收的数据包集合与 PIFO 接收的数据包集合高度相似。

从整体上看，这两个组件的工作方式如下：

- **时间组件（Temporal component）**  
    准入控制的阈值是**动态变化的，而不是固定的**。该阈值会根据实时的**到达速率与离开速率之间的差异**进行更新。当到达速率显著高于离开速率时，阈值会变得更加严格，从而限制准入的数据包数量。这样可以保证被接收的数据包速率大致与系统的发送速率相匹配。
    
- **空间组件（Spatial component）**  
    准入控制会**根据数据包的 rank 区分对待不同数据包**，而不是采用与 rank 无关的简单策略（例如随机丢弃 10% 的数据包）。系统更倾向于丢弃 **高-rank（低优先级）** 的数据包，而保留 **低-rank（高优先级）** 的数据包，因为低-rank 数据包预计会更早被调度。准入阈值根据不同 rank 数据包的到达速率分布来确定，从而保证被接收的数据包在 rank 分布上与 PIFO 接收的数据包相似。
    
我们注意到，这种**动态、比例式调节（dynamic, proportional adaptation）**的基本思想已被广泛应用，尤其是在网络领域中的拥塞控制机制中。例如：
- 基于时延的拥塞控制算法（如 TIMELY 和 Swift）会根据端到端时延动态调整 TCP 窗口大小；
- 基于 ECN 的算法（如 DCTCP）会根据被打上 ECN 标记的数据包数量按比例调整窗口大小。
    
这些机制都将控制逻辑放在**端主机（end hosts）**上。相比之下，**AIFO 将这种动态、比例调节机制放置在网络内部**，并用于一个完全不同的目的——**可编程分组调度（programmable packet scheduling）**。

这一背景对算法设计提出了非常严格的要求：算法不仅要在性能上接近最优，还必须能够在**现有硬件的数据平面上以线速（line rate）运行**。

对于熟悉分组调度研究的读者来说，可以将 AIFO 看作是一种 **AQM（主动队列管理）方案**。传统的 AQM 方案通常针对某一个特定目标，通过将平均队列长度或时延估计值与阈值进行比较来决定是否丢包。相比之下，**AIFO 被设计为一种通用机制**，可以被编程以支持不同的调度目标，其丢包决策同时基于：
- 阈值比较（时间组件），以及
- 相对的数据包 rank 估计（空间组件）。
### Algorithm
我们基于上述关键思想设计了 AIFO。**算法 1** 给出了其伪代码。

在**入口（ingress，1–8 行）**，AIFO 使用**准入控制**（第 2–5 行）来决定一个到达的数据包是被**入队**（第 6 行）还是被**丢弃**（第 8 行）。准入阈值由**当前队列长度** (c) 和**队列大小** (C) 动态决定，同时使用**分位数估计**$(W.\text{quantile(pkt)})$来估计当前数据包的**相对 rank**。队列本身是一个 FIFO 队列，新到的数据包被插入到队尾。

在**出口（egress，9–12 行）**，当队列非空时，AIFO 从队首取出一个数据包并发送出去。

时间组件使用**当前队列长度**（记为 (c)）与**目标队列大小**（记为 (C)）之间的差值，来刻画**到达速率与离开速率之间的偏差**。当当前队列长度接近目标队列大小时（即 (C - c) 较小），准入控制的阈值会变得更加严格。

我们通过一个参数 (k) 分配一段 **headroom（余量）**，用于容忍小规模的突发流量。当队列长度处于 headroom 范围内（即 (c \le k \cdot C)）时，**所有数据包都会被接收**。相应地，为了反映 headroom 的存在，队列长度与队列大小之间的差值还会乘以一个缩放因子 (\frac{1}{1-k})。

为了表述清晰，在算法第 5 行中，我们将以下两个条件分开写出：

- $c \le k \cdot C$
    
- $W.\text{quantile(pkt)} \le \frac{1}{1-k} \cdot \frac{C-c}{C}$
    

从数学角度来看，第一个条件 $c \le k \cdot C$ 是冗余的。因为当 $c \le k \cdot C$ 时，有  
$$
\frac{1}{1-k} \cdot \frac{C-c}{C} \ge 1 \ge W.\text{quantile(pkt)}  
$$
其中 $W.\text{quantile(pkt)}$ 表示对数据包 rank 分位数的估计，因此该数据包必然会被接收。

需要注意的是，**$C$ 并不一定等于 FIFO 队列的物理大小**。商用交换机中队列的物理大小因 ASIC 不同而差异很大，从几十个数据包到几百甚至上千个数据包不等。尽管硬件支持较大的缓冲区，但在实际生产网络中，为了降低时延，通常会使用**浅缓冲（shallow buffers）**并限制队列长度。因此，在算法描述中，$C$ 被配置为一个**小于物理队列大小的值**，我们将其称为**目标队列大小（target queue size）**，而非物理队列大小。

在空间组件中，AIFO 维护一个**最近到达数据包的滑动窗口**，并使用到达数据包 rank 的**分位数**$(W.\text{quantile(pkt)}$ 作为准入判据。

当数据包的 rank 分位数不大于  
$$  
\frac{1}{1-k} \cdot \frac{C-c}{C}  
$$
时，数据包被接收；否则，数据包被丢弃。

其直觉在于：在考虑 headroom（通过 $\frac{1}{1-k}$ 进行修正）之后，$\frac{C-c}{C}$ 表示**剩余队列空间占目标队列长度的比例**。只有一部分后续到达的数据包能够填满这部分剩余空间。我们找到一个 rank 阈值 $r^*$，使得其分位数等于剩余队列空间所对应的比例，并且**只接收 rank 不大于 $r^*$ 的数据包**。这样可以确保被接收的数据包集合主要由**低-rank（高优先级）数据包**组成，并且它们正好能够填满剩余的队列空间。

滑动窗口用于根据历史到达的数据包，对当前数据包的 rank 分位数进行估计。

二维准入控制的一个重要优势在于：**一个组件的不准确性可以由另一个组件进行补偿**。例如，如果滑动窗口的分位数估计（空间组件）略有偏差，导致接收了额外的数据包，那么队列长度 (c) 会随之增大，从而使得分位数阈值  
$$
\frac{1}{1-k} \cdot \frac{C-c}{C}  
$$
（时间组件）变得更加严格。这种变化会反过来迫使空间组件使用一个更小的 rank 阈值，从而纠正之前的偏差。
